# Multi-Dataset Aircraft Representation Learning – 기술 보고서

## 1. 요약(Executive Summary)

본 보고서는 **PlanesNet**, **HRPlanes**, **FGVC Aircraft** 세 가지 항공기 이미지 데이터셋을 동시에 학습하는 멀티 데이터셋 항공기 표현 학습 파이프라인의 구현 및 실험 결과를 정리한 문서이다. 제안된 시스템은 하나의 스크립트(`src/train_multidataset.py`) 안에서 CLIP 스타일의 대조 학습(contrastive learning), 회전 기반 증강(rotation-oriented augmentation), 분할(segmentation)을 위한 보조 UNet 디코더, DiT 기반의 특성 정제(refinement) 블록, BERT 기반 텍스트 프롬프트를 통합하였다.  

CPU 환경에서 5 에폭 동안 학습한 결과, 위성 기반 데이터셋인 PlanesNet과 HRPlanes에서는 **안정적인 수렴(stable convergence)**을 보였으며, 5 에폭 시점에 PlanesNet 검증 정확도는 **97.47%**, HRPlanes는 **100%**에 도달하였다. 반면, 세밀 분류(fine-grained) 데이터셋인 FGVC Aircraft의 검증 정확도는 **1–2%대**에 머물러 여전히 충분히 학습되지 않은 상태로 남아 있다. 이는 현재의 아키텍처와 학습 설정이 원격 탐사(remote sensing) 기반 이진/중간 수준 분류에는 적합하지만, 세밀한 항공기 기종 분류를 위해서는 추가적인 용량 확장 또는 데이터셋 특화 튜닝이 필요함을 시사한다.

---

## 2. 시스템 개요 (System Overview)

### 2.1 데이터셋

- **PlanesNet**
  - 위성 이미지 패치 상에서의 이진 분류 (비행기 존재 / 비존재).
  - 클래스 불균형이 존재하며, 배경(건물, 도로, 농지 등)의 변화가 크다.

- **HRPlanes**
  - 항공기가 어노테이션된 고해상도 항공/위성 이미지.
  - 제공된 바운딩 박스를 세그멘테이션 마스크로 변환하여:
    - 비행기 존재 여부 분류(classification)
    - HRPlanes 전용 보조 UNet 디코더를 통한 세그멘테이션(segmentation) 학습에 활용한다.

- **FGVC Aircraft**
  - 시각적으로 매우 유사한 항공기 기종들이 포함된 세밀 분류(fine-grained) 데이터셋.
  - 멀티 데이터셋 학습 상황에서 CLIP 스타일 표현과 분류 헤드의 한계를 테스트하기 위한 용도로 활용하였다.

### 2.2 모델 구조 (Architecture)

- **백본(Backbone)**
  - CLIP에서 영감을 받은 CNN/ResNet 스타일 비전 백본:
    - 단순한 2-레이어 CNN 대신, 더 깊은 residual 스택 구조를 사용.
    - 최종 투영(projection) 차원은 BERT 임베딩 크기와 정렬(alignment)되도록 설계.

- **헤드(Heads)**
  - **데이터셋별 분류 헤드 (dataset-specific classifier heads)**:
    - PlanesNet, HRPlanes, FGVC 각각에 대해 독립적인 분류 레이어를 구성.
    - 필요 시 추가 용량 확보를 위한 히든 레이어를 선택적으로 포함 가능.
  - **UNet 디코더 (HRPlanes 전용)**:
    - 백본으로부터 multi-scale 피처를 받아 세그멘테이션 디코딩.
    - HRPlanes 마스크와 해상도가 일치하도록 로짓을 출력한다.

- **텍스트 인코더 및 프롬프트 (Text Encoder & Prompts)**
  - **BERT**를 사용하여 다음과 같은 텍스트 프롬프트를 임베딩:
    - “satellite image of an airplane”
    - “no airplane”
    - “side view of a commercial jet”
  - 인코딩된 텍스트 임베딩은 전용 텍스트 디바이스에 캐시하여 반복 계산 비용을 줄인다.

### 2.3 손실 함수 (Loss Functions)

각 데이터셋에 대해 총 손실(total loss)은 다음 세 가지 항목의 가중 합으로 구성된다.

- **분류 손실(`cls_loss`)**
  - 예측된 로짓과 정답 레이블 간의 크로스 엔트로피(cross-entropy).
  - 모든 데이터셋(PlanesNet, HRPlanes, FGVC)에 공통적으로 적용된다.

- **세그멘테이션 손실(`seg_loss`)**
  - HRPlanes 마스크에 대해 정의되는 이진 또는 다중 클래스 세그멘테이션 손실(BCE/CE 등).
  - UNet 디코더 출력 크기가 마스크와 다를 경우, 인터폴레이션(보통 bilinear)을 통해 해상도를 맞춘 뒤 손실을 계산한다.

- **CLIP 대조 손실(`clip_loss`)**
  - 이미지 임베딩과 BERT 텍스트 임베딩 사이의 대조 손실(contrastive loss).
  - 시각적 표현과 의미적 표현 간 정렬(alignment)을 유도하기 위한 목적이다.

로그에 기록된 `total_loss`는 위 세 손실의 조합을 반영한다.

### 2.4 디바이스 구성 (Devices)

- 비전 백본과 UNet 디코더는 `--vision-device` 상에서 실행된다.
- BERT 텍스트 인코더 및 캐시된 텍스트 임베딩은 `--text-device`에 배치된다.
- CUDA가 없는 환경을 위해, 전 파이프라인은 CPU 전용 모드도 지원한다.

---

## 3. 개발 과정에서의 이슈 및 해결 (Development Challenges & Fixes)

구현 과정에서 여러 통합 및 안정성 이슈가 발견되었으며, 이를 단계적으로 해결하였다. 주요 문제와 해결책은 아래 표와 같다.

| 이슈 | 원인 | 해결 |
| --- | --- | --- |
| 학습 시작 시 CUDA assertion 발생 | PyTorch가 CUDA 없이 빌드되었거나 드라이버 버전이 맞지 않음 | 명시적인 CPU 실행 옵션(`--vision-device cpu`)과 CPU 전용 실행 가이드 추가. |
| 대조 손실 차원 불일치 | 비전 백본은 512차원, BERT는 768차원 임베딩 출력 | 백본 최종 투영 차원을 768차원으로 확장하고, 투영된 벡터를 DiT 및 분류 헤드로 일관되게 전달. |
| HRPlanes 배치 메타데이터 오류 | 가변 길이의 바운딩 박스 리스트가 배치 메타데이터에 포함됨 | 배치 메타데이터에서 per-sample `boxes`를 제거하고, 텐서 형태(이미지, 마스크, 레이블)만 콜레이트. |
| 세그멘테이션 손실 크기 불일치 | UNet 출력이 32×32, 정답 마스크는 256×256 | UNet 로짓을 bilinear 업샘플링하여 마스크 해상도에 맞춘 뒤 BCE/CE 손실 계산. |
| `results/` 디렉터리 산출물이 Git에 추적되지 않음 | `results/` 전체를 무시하는 .gitignore 규칙 때문에 로그/플롯까지 제외됨 | ignore 규칙을 세분화하고, `results/logs/**`, `results/plots/**`는 명시적으로 허용하는 예외 규칙 추가. |

이러한 수정으로, CPU 환경에서도 안정적으로 실행되며, 모든 주요 지표와 시각화를 기록하는 멀티 데이터셋 학습 루프가 완성되었다.

---

## 4. 데이터셋별 학습 동역학 (Training Dynamics Across Datasets)

본 절에서는 CLIP 스타일 백본, UNet, DiT 구성으로 5 에폭 학습을 수행했을 때, 각 데이터셋에서 관찰된 로그를 기반으로 학습 경향을 분석한다.

### 4.1 PlanesNet

**학습(분류 + CLIP)**  

- 학습 분류 손실은 1 에폭에서 약 **0.34**에서 시작해 5 에폭에는 **0.13** 수준까지 감소하였다.  
- 학습 정확도는 **85.7%**에서 **95.3%**까지 꾸준히 상승하였다.  
- PlanesNet에 대한 CLIP 손실은 대략 **3.05–3.25** 범위에서 안정적으로 유지되며, 최적화 전체를 지배하기보다는 정규화(regularizer) 역할을 수행한다.

**검증(Validation)**  

- 검증 손실은 에폭이 진행될수록 단조롭게 감소하였다.
  - **0.236 → 0.120 → 0.128 → 0.097 → 0.076** (1–5 에폭).
- 검증 정확도는 다음과 같이 지속적으로 향상되었다.
  - **92.41% → 95.63% → 95.78% → 96.53% → 97.47%.**

**해석**  
PlanesNet에서는 학습/검증 정확도가 함께 상승하고 검증 손실도 지속적으로 감소하는 **안정적인 수렴 패턴**이 관찰된다. 명확한 오버피팅 징후 없이 3 에폭 근처에서 이미 95% 이상의 검증 정확도를 달성하며, 5 에폭까지 학습하면 약 97.5%까지 도달한다. PlanesNet만을 고려한다면, 3 에폭 지점에서 early stopping을 적용해도 충분히 높은 성능을 확보할 수 있다.

---

### 4.2 HRPlanes

**학습(분류 + 세그멘테이션 + CLIP)**  

- HRPlanes의 학습 분류 손실은 1 에폭에서 약 **0.41** 수준에서 출발하여 5 에폭에는 **0.013**까지 감소하였다.  
- 세그멘테이션 손실은 약 **0.76**에서 **0.50** 정도로 감소하며, UNet 디코더가 항공기 마스크를 점진적으로 학습하고 있음을 보여준다.  
- 학습 정확도는 초기부터 매우 높으며, **98.41%**에서 시작하여 3 에폭 이후에는 **99.47–100%** 수준을 유지한다.

**검증(Validation)**  

- 검증 분류 손실은 1 에폭에서 **0.140** 수준에서 출발해 5 에폭에는 약 **0.00025** 수준으로 수렴한다.  
- 검증 정확도는 모든 에폭에서 **100%**로 유지된다.  
- 검증 세그멘테이션 손실은 **0.75 → 0.76 → 2.64 → 1.15 → 0.83**처럼 다소 변동성이 크다. 이는 픽셀 단위 세그멘테이션 자체가 이진 분류보다 난이도가 높은 데다, 검증 샘플 수가 상대적으로 적은 점에 기인한 것으로 해석할 수 있다.

**해석**  
HRPlanes의 분류 문제는 현재 아키텍처와 학습 설정 하에서 사실상 **완전히 해결된 상태**라고 볼 수 있다. 모델은 초기 에폭부터 완전한 검증 정확도(100%)에 도달하여 이를 유지한다. 세그멘테이션 브랜치는 학습 손실 감소를 통해 점진적으로 향상되고 있지만, 검증 기준으로는 여전히 일부 불안정성이 존재한다. 전반적으로 HRPlanes 결과는 CLIP 스타일 백본과 UNet 디코더가 고해상도 항공 이미지를 처리하기에 충분한 용량을 가지고 있음을 보여준다.

---

### 4.3 FGVC Aircraft

**학습(분류 + CLIP)**  

- 학습 분류 손실은 1 에폭 **4.62**에서 5 에폭 **4.47** 수준으로 소폭 감소하는 데 그친다.  
- FGVC에 대한 CLIP 손실도 약 **3.47 → 3.40** 정도로 매우 완만하게 감소한다.  
- 학습 정확도는 다음과 같이 소폭 상승하지만 전반적으로 매우 낮다.
  - **0.81% → 1.35% → 1.95% → 1.77% → 2.64%.**

**검증(Validation)**  

- 검증 손실은 모든 에폭에서 **4.51–4.61** 범위에 머무른다.  
- 검증 정확도 역시 약간의 상승만 보이며, 여전히 극히 낮다.
  - **1.26% → 1.62% → 1.47% → 2.25% → 2.37%.**

**해석**  
위성 기반 데이터셋들과 달리, FGVC Aircraft는 현 멀티 데이터셋 학습 설정에서 **명확한 언더피팅(underfitting)** 상태를 보인다. 여러 에폭 동안 학습했음에도 성능이 사실상 랜덤 수준에 머무르고 있으며, 그 원인으로는 다음과 같은 점을 들 수 있다.

- FGVC가 다수의 유사한 항공기 기종을 포함하는 **고난도 세밀 분류 과제**라는 점.
- 상대적으로 쉽게 수렴하는 PlanesNet/HRPlanes에 최적화가 더 집중되는 구조로 인해, FGVC에 충분한 용량과 학습 신호가 전달되지 않았을 가능성.
- 현재 구조가 FGVC에 특화된 설계를 갖추지 못한 점:
  - 예: 더 높은 해상도의 입력, 더 깊은 분류 헤드, 클래스별 균형을 고려한 샘플링 전략 등이 부족함.

이 결과는 제안된 통합 파이프라인이 **이진 항공기 분류 및 중간 난이도 원격 탐지 과제에는 충분히 효과적**이지만, **고난도 세밀 항공기 인식(fine-grained recognition)**을 해결하기 위해서는 다음과 같은 추가적인 작업이 필요함을 보여준다.

- 데이터셋 간 손실 가중치 재조정(loss re-balancing).
- FGVC 전용 분류 헤드 용량 증가.
- FGVC만을 대상으로 하는 후속 파인튜닝 스테이지 구성 등.

---

### 4.4 멀티 데이터셋 학습 성질 요약

- **PlanesNet**: 수렴이 빠르고 매끄러우며, 5 에폭 시점에 검증 정확도 약 97.5%를 기록. 오버피팅 징후는 뚜렷하지 않다.
- **HRPlanes**: 분류 정확도는 초반부터 100%에 도달하며 유지됨. 세그멘테이션은 점진적으로 개선되지만 검증 기준으로는 변동성이 있다.
- **FGVC Aircraft**: 멀티 데이터셋 설정에서 충분히 학습되지 못한 상태로, 약 2–3% 수준의 정확도에서 정체. 과제 특화 구조 및 하이퍼파라미터 조정이 필요하다.

종합하면, **공유된 CLIP 스타일 피처 + 가벼운 데이터셋별 헤드 구조는 원격 탐사 위성 이미지 기반 이진/중간 난이도 과제에는 충분하지만**, 추가적인 특화 없이 **고난도 세밀 분류에는 아직 적합하지 않다**는 결론을 얻을 수 있다.

---

## 5. 시각화 모듈 (Visualization Suite)

학습 동작을 정량적으로 파악하고 보고서/발표 자료에 활용하기 위해, 프로젝트에는 전용 시각화 모듈(`src/visualize.py`)이 포함되어 있다. 이 모듈은 `results/logs/` 하위의 JSON 로그를 입력으로 받아, 요구된 6가지 그래프를 생성한다.

1. **막대 그래프 (Bar Plot)**
   - 데이터셋별 클래스 분포 혹은 샘플 개수를 표현.
   - PlanesNet, HRPlanes, FGVC 간 데이터 불균형을 시각적으로 보여주는 용도.

2. **선 그래프 (Line Plot)**
   - 에폭에 따른 각 데이터셋의 학습/검증 정확도 변화를 표현.
   - PlanesNet과 HRPlanes가 빠르게 수렴하는 양상과, FGVC가 뒤처지는 양상을 한눈에 확인 가능.

3. **박스플롯 (Box Plot)**
   - 데이터셋별 학습 손실(예: `total_loss`, `cls_loss`) 분포를 표현.
   - 위성 데이터셋에 비해 FGVC가 일관되게 높은 손실 구간에 머무르는 것을 강조한다.

4. **히트맵 (Heatmap)**
   - 에폭/데이터셋 간 검증 정확도 또는 손실 상관관계 행렬.
   - 한 데이터셋의 개선이 다른 데이터셋의 개선 또는 악화와 어떤 상관을 가지는지 파악하는 용도.

5. **산점도 (Scatter Plot)**
   - 각 에폭마다 데이터셋별 학습 정확도 vs. 검증 정확도를 좌표에 표시.
   - PlanesNet/HRPlanes는 대각선 부근(학습/검증 성능 일치)에 위치하는 반면, FGVC는 원점 근처에 몰리는 특성을 보여준다.

6. **히스토그램 (Histogram)**
   - 데이터셋별 CLIP 대조 손실 분포를 시각화.
   - CLIP 정렬 성능이 모든 데이터셋에서 균일하게 개선되는지, 혹은 상대적으로 쉬운 데이터셋에만 집중되는지 판단할 수 있다.

이러한 시각화는 모델 디버깅뿐만 아니라, 최종 보고서 및 발표 자료에서 실험 결과를 설득력 있게 제시하기 위한 근거 자료로 활용된다.

---

## 6. 결론 및 향후 과제 (Conclusions and Future Work)

현재의 멀티 데이터셋 학습 파이프라인은 다음과 같은 성과를 보인다.

- **CLIP 스타일 대조 학습**, **회전 기반 증강**, **UNet 세그멘테이션**, **DiT 정제 블록**, **BERT 기반 텍스트 프롬프트**를 하나의 스크립트 내에 통합하는 데 성공하였다.
- PlanesNet과 HRPlanes에 대해서는 **높은 수준의 성능**을 달성하였다.
  - PlanesNet: 5 에폭 기준 검증 정확도 약 97.5%.
  - HRPlanes: 전 에폭에서 검증 정확도 100% 유지, 세그멘테이션 성능도 점진적으로 향상.
- 데이터셋별 학습 양상을 세밀하게 드러내는 **로그 및 시각화 환경**을 구축하여, 오버피팅/언더피팅 및 데이터셋 간 트레이드오프를 쉽게 진단할 수 있게 하였다.

동시에, 실험 결과는 다음과 같은 분명한 한계도 보여준다.

- 동일한 파이프라인은 **FGVC Aircraft**와 같은 고난도 세밀 분류 과제에 대해서는 아직 충분한 성능을 내지 못하고 있으며, 멀티 데이터셋 설정 5 에폭 기준 약 2–3% 수준의 정확도에 머물고 있다.

따라서 향후 연구 방향은 다음과 같이 정리할 수 있다.

1. **멀티 태스크 손실 재조정(Re-balancing Multi-Task Training)**
   - 상대적으로 쉬운 PlanesNet/HRPlanes 대비 FGVC에 더 강한 그라디언트 신호가 전달되도록 손실 가중치를 조정.

2. **FGVC 특화 파인튜닝(FGVC-Specific Fine-Tuning)**
   - 더 높은 입력 해상도, 더 깊은 분류 헤드, 클래스 균형을 고려한 샘플링 등 FGVC에 특화된 설정으로 별도의 파인튜닝 스테이지를 수행.

3. **세그멘테이션 감독 강화(Improved Segmentation Supervision)**
   - HRPlanes 마스크 품질 및 UNet 구조를 개선하여, 검증 세그멘테이션 손실의 변동성을 줄이고 안정적으로 성능을 향상.

4. **조기 종료 및 스케줄링(Early Stopping and Scheduling)**
   - PlanesNet/HRPlanes는 수렴 시점에 조기 종료하고, FGVC에 더 많은 에폭을 할당하는 등 데이터셋 인지형 스케줄링 전략을 도입.

5. **GPU 가속(GPU Acceleration)**
   - CPU 기반 실험에서 GPU 지원 PyTorch 환경으로 이관하여 에폭 수를 늘리고, 보다 공격적인 하이퍼파라미터 탐색을 수행.

요약하면, 본 시스템은 **원격 탐사 기반 멀티 데이터셋 항공기 표현 학습**을 위한 견고한 베이스라인을 제공하며, 이를 바탕으로 **세밀 항공기 인식(fine-grained aircraft recognition)**으로 확장하기 위한 명확한 개선 방향을 제시한다.
